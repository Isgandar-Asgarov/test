{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# torture"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": "import sqlite3\nimport urllib.error\nimport ssl\nfrom urllib.parse import urljoin\nfrom urllib.parse import urlparse\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup\nimport re\nctx = ssl.create_default_context()\nctx.check_hostname = False\nctx.verify_mode = ssl.CERT_NONE\n\ncon = sqlite3.connect(\"helpme.sqlite3\")\ncur = con.cursor()\ncur.executescript(\"\"\"create table if not exists Origins (site text unique);\n                create table if not exists Pages (id integer primary key, page text unique, html TEXT, error text, old_rank real, new_rank real);\n                create table if not exists mtm (from_page integer, to_page integer, unique(from_page, to_page))\"\"\")\n\nwhile True:\n    site = input(\"start page?: \")\n    if site == \"done\":\n        break\n    else:pass\n    cur.execute(\"select page from Pages where page = ?\", (site,))\n    if cur.fetchone() is not None:\n        print(\"already in database\")\n        continue\n    else:pass\n    if len(site)<1:\n        cur.execute('SELECT id, page, html FROM Pages ORDER BY RANDOM() LIMIT 1')\n        site2 = cur.fetchone()\n        try:\n            site = site2[1][:re.search(r\"\\.[a-z]{2,3}(/)\", site2[1]).span()[1] - 1]\n        except:\n            print(\"couldn't extract domain\")\n            continue\n        html = BeautifulSoup(site2[2], \"html.parser\")\n        site2 = site2[0]\n    else:\n        try:\n            site1 = urlopen(site, context=ctx)\n            html = BeautifulSoup(site1.read(), \"html.parser\")\n            cur.execute('INSERT OR IGNORE INTO Pages (page, html, error) VALUES ( ?, ?, ?)',\n                        (site, html.prettify(), site1.getcode()))\n            cur.execute('SELECT id, page FROM Pages where page = ?', (site,))\n            site2 = cur.fetchone()[0]\n            site = site[:re.search(r\"\\.[a-z]{2,3}(/)\", site).span()[1] - 1]\n            cur.execute('INSERT OR IGNORE INTO Origins (site) VALUES ( ? )', (site,))\n        except:\n            print(\"smth fucked up\")\n            continue\n    for tag in html('a'):\n        try:\n            href = tag.get('href', None)\n            if site not in href:\n                continue\n            else:\n                ipos = href.find('#')\n                if ipos > 1:\n                    href = href[:ipos]\n                if href.endswith('.png') or href.endswith('.jpg') or href.endswith('.gif'):\n                    continue\n                if href.endswith('/'):\n                    href = href[:-1]\n                html = BeautifulSoup(urlopen(href, context=ctx).read(), \"html.parser\")\n                cur.execute('INSERT OR IGNORE INTO Pages (page, html, error) VALUES ( ?, ?, ?)', (href, html.prettify(), urlopen(href, context=ctx).getcode()))\n                cur.execute(\"select id from Pages where page = ?\", (href,))\n                site3 = cur.fetchone()[0]\n                cur.execute('INSERT OR IGNORE INTO mtm (from_page, to_page) VALUES ( ?, ?)',\n                            (site2, site3))\n        except:\n            continue\n    con.commit()"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}